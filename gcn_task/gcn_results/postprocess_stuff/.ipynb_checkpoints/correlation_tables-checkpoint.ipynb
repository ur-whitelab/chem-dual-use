{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e40a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime\n",
    "\n",
    "import cairosvg\n",
    "#import dataframe_image as dfi\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import skunk\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "sys.path.insert(1,'../../')\n",
    "from dglgcn import compute_threshold_from_split\n",
    "\n",
    "sys.path.insert(1, '/path/to/application/app/folder')\n",
    "today_date = datetime.today().date()\n",
    "time_now = datetime.today().ctime()\n",
    "\n",
    "# packages & settings for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as font_manager\n",
    "import urllib.request\n",
    "\n",
    "urllib.request.urlretrieve('https://github.com/google/fonts/raw/main/ofl/ibmplexmono/IBMPlexMono-Regular.ttf', 'IBMPlexMono-Regular.ttf')\n",
    "fe = font_manager.FontEntry(\n",
    "    fname='IBMPlexMono-Regular.ttf',\n",
    "    name='plexmono')\n",
    "font_manager.fontManager.ttflist.append(fe)\n",
    "plt.rcParams.update({'axes.facecolor':'#f5f4e9',\n",
    "            'grid.color' : '#AAAAAA',\n",
    "            'axes.edgecolor':'#333333',\n",
    "            'figure.facecolor':'#FFFFFF',\n",
    "            'axes.grid': False,\n",
    "                     \n",
    "            'axes.prop_cycle':   plt.cycler('color', plt.cm.Dark2.colors),\n",
    "            'font.family': fe.name,\n",
    "            'figure.figsize': (3.5,3.5 / 1.2),\n",
    "            'ytick.left': True,\n",
    "            'xtick.bottom': True   ,\n",
    "            'figure.dpi': 300\n",
    "           })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e4e122",
   "metadata": {},
   "outputs": [],
   "source": [
    "censor_region = \"above\"\n",
    "censor_splits = [0.1, 0.5, 0.9]\n",
    "run_date = '2024-05-06'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699cc291",
   "metadata": {},
   "outputs": [],
   "source": [
    "urllib.request.urlretrieve(\n",
    "    \"https://deepchemdata.s3-us-west-1.amazonaws.com/datasets/Lipophilicity.csv\",\n",
    "    \"./lipophilicity.csv\",\n",
    ")\n",
    "lipodata = pd.read_csv(\"./lipophilicity.csv\")\n",
    "lipodata = list(zip(lipodata.smiles,lipodata.exp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c03d453",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataframe(censor_split, censor_type, output_dir=None, ending=\"\", hasNaN=False):\n",
    "    task = f'{censor_type}_results_split{censor_split}_{censor_region}{ending}'\n",
    "    if output_dir is None:\n",
    "        dir_name = f'../all_results/gcn_{task}'\n",
    "    else: \n",
    "        dir_name = output_dir + f'all_results/gcn_{task}'\n",
    "    labels = [label for _, label in lipodata]\n",
    "    threshold = compute_threshold_from_split(labels, censor_split, censor_region)\n",
    "    print(f'For censor split {censor_split}, Threshold =',threshold)\n",
    "    \n",
    "    if hasNaN and censor_split == 0.9:\n",
    "        # special case for omitting 90% sensitive data --> often gets NaN for correlation values\n",
    "        file_path = f'{dir_name}/dataframe_{run_date}_revised.json'\n",
    "        #ax.set_title(f'{censor_split * 100:.0f}% sensitive data$^*$') # add asterisk\n",
    "    else:\n",
    "        file_path = f'{dir_name}/dataframe_{run_date}.json'\n",
    "        \n",
    "    \n",
    "    # load json file and plot results\n",
    "    df = pd.read_json(file_path)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c052927a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_date = '2024-05-11'\n",
    "df1 = load_dataframe(censor_splits[0], 'omit', ending=\"_150epochs\", hasNaN=True)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db14664",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df0 = df1[['omit frac']]\n",
    "df1 = df1[['lower corr', 'upper corr']]\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381b0c88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df2 = load_dataframe(censor_splits[1], 'omit', ending=\"_150epochs\", hasNaN=True)\n",
    "df2 = df2[['lower corr', 'upper corr']]\n",
    "df3 = load_dataframe(censor_splits[2], 'omit', ending=\"_150epochs\", hasNaN=True)\n",
    "df3 = df3[['lower corr', 'upper corr']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8071e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "omit_df = pd.concat(dict( SensitiveSplit10 = df1, SensitiveSplit50 = df2, SensitiveSplit90 = df3), axis=1)\n",
    "omit_df = omit_df.set_index(df0['omit frac'])\n",
    "#omit_df.to_csv('gcn_omit_table.csv')\n",
    "omit_df\n",
    "# todo: save using dataframe_image after installing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42ea6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_date = '2024-05-11'\n",
    "df1 = load_dataframe(censor_splits[0], 'ynoise')\n",
    "df0 = df1[['y noise level']]\n",
    "df1 = df1[['lower corr', 'upper corr']]\n",
    "df2 = load_dataframe(censor_splits[1], 'ynoise')\n",
    "df2 = df2[['lower corr', 'upper corr']]\n",
    "df3 = load_dataframe(censor_splits[2], 'ynoise')\n",
    "df3 = df3[['lower corr', 'upper corr']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6578ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ynoise_df = pd.concat(dict( SensitiveSplit10 = df1, SensitiveSplit50 = df2, SensitiveSplit90 = df3), axis=1)\n",
    "ynoise_df = ynoise_df.set_index(df0['y noise level'])\n",
    "#ynoise_df.to_csv('gcn_ynoise_table.csv')\n",
    "ynoise_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c904efc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_date = '2024-05-06'\n",
    "df1 = load_dataframe(censor_splits[0], 'xnoise')\n",
    "df0 = df1[['similarity scores']]\n",
    "df1 = df1[['lower corr', 'upper corr']]\n",
    "df2 = load_dataframe(censor_splits[1], 'xnoise')\n",
    "df2 = df2[['lower corr', 'upper corr']]\n",
    "df3 = load_dataframe(censor_splits[2], 'xnoise')\n",
    "df3 = df3[['lower corr', 'upper corr']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ab781d",
   "metadata": {},
   "outputs": [],
   "source": [
    "xnoise_df = pd.concat(dict( SensitiveSplit10 = df1, SensitiveSplit50 = df2, SensitiveSplit90 = df3), axis=1)\n",
    "xnoise_df = xnoise_df.set_index(df0['similarity scores'])\n",
    "#xnoise_df.to_csv('gcn_xnoise_table.csv')\n",
    "xnoise_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dualusage",
   "language": "python",
   "name": "dualusage"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
