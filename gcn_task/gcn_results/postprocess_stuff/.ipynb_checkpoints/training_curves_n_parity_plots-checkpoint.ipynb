{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54840622",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import spearmanr\n",
    "import torch\n",
    "\n",
    "\n",
    "sys.path.insert(1,'../../')\n",
    "from dglgcn import compute_threshold_from_split\n",
    "\n",
    "sys.path.insert(1, '/path/to/application/app/folder')\n",
    "today_date = datetime.today().date()\n",
    "time_now = datetime.today().ctime()\n",
    "\n",
    "# packages for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as font_manager\n",
    "import urllib.request\n",
    "\n",
    "urllib.request.urlretrieve('https://github.com/google/fonts/raw/main/ofl/ibmplexmono/IBMPlexMono-Regular.ttf', 'IBMPlexMono-Regular.ttf')\n",
    "fe = font_manager.FontEntry(\n",
    "    fname='IBMPlexMono-Regular.ttf',\n",
    "    name='plexmono')\n",
    "font_manager.fontManager.ttflist.append(fe)\n",
    "plt.rcParams.update({'axes.facecolor':'#f5f4e9',\n",
    "            'grid.color' : '#AAAAAA',\n",
    "            'axes.edgecolor':'#333333',\n",
    "            'figure.facecolor':'#FFFFFF',\n",
    "            'axes.grid': False,\n",
    "            'axes.prop_cycle':   plt.cycler('color', plt.cm.Dark2.colors),\n",
    "            'font.family': fe.name,\n",
    "            'figure.figsize': (3.5,3.5 / 1.2),\n",
    "            'ytick.left': True,\n",
    "            'xtick.bottom': True   ,\n",
    "            'figure.dpi': 300\n",
    "           })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53914fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "censor_region = \"above\"\n",
    "censor_splits = [0.1, 0.5, 0.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828c05a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "urllib.request.urlretrieve(\n",
    "    \"https://deepchemdata.s3-us-west-1.amazonaws.com/datasets/Lipophilicity.csv\",\n",
    "    \"./lipophilicity.csv\",\n",
    ")\n",
    "lipodata = pd.read_csv(\"./lipophilicity.csv\")\n",
    "data = list(zip(lipodata.smiles,lipodata.exp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23472f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = f'omit_results_split{split}_{censor_region}'\n",
    "dir_name = f'../all_results/gcn_{task}'\n",
    "\n",
    "for trial in range(1):  # Trials from 0 to 4\n",
    "    for omit in omit_fractions:  # Omit fractions from 0.0 to 1.0\n",
    "        file_name = f\"{dir_name}/trainingcurve_trial{trial}_omit_{omit}.json\"\n",
    "        with open(file_name, 'r') as file:\n",
    "            epochs, train_loss, val_loss = json.load(file)\n",
    "            actual_epochs = epochs[:len(train_loss)]\n",
    "        plt.plot(actual_epochs, train_loss, label='Train Loss', color='C0')\n",
    "        plt.plot(actual_epochs, val_loss, label='Validation Loss', color='C1')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title(f'Omit Fraction {omit:.1f}')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573ed6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_multiple_training_curves(censor_split, censor_type, censor_intervals, results_dir=None):\n",
    "    task = f'{censor_type}_results_split{censor_split}_{censor_region}'\n",
    "    if results_dir == None:\n",
    "        results_dir = f'../all_results/gcn_{task}'\n",
    "    \n",
    "    ncols = len(censor_intervals)\n",
    "    fig, axs = plt.subplots(nrows=5, ncols=ncols, sharey=True, figsize=(ncols*2+5, 12), dpi=300)\n",
    "    \n",
    "    for i in range(5):  # Trials from 0 to 4\n",
    "        for j, c in enumerate(censor_intervals):  # Omit fractions from 0.0 to 1.0\n",
    "            ax = axs[i,j]\n",
    "            # ax = axs[i][j]\n",
    "            file_name = f\"{results_dir}/trainingcurve_trial{i}_{censor_type}_{c}.json\"\n",
    "            with open(file_name, 'r') as file:\n",
    "                epochs, train_loss, val_loss = json.load(file)\n",
    "                actual_epochs = epochs[:len(train_loss)]\n",
    "            ax.plot(actual_epochs, train_loss, label='Train Loss', color='C0')\n",
    "            ax.plot(actual_epochs, val_loss, label='Val Loss', color='C1')\n",
    "            if i == 0:\n",
    "                if censor_type == 'omit':\n",
    "                    ax.set_title(f'Omit Fraction {c:.1f}')\n",
    "                elif censor_type == 'xnoise':\n",
    "                    ax.set_title(f'Similarity {c}')\n",
    "                else: \n",
    "                    ax.set_title(f'Y Noise level {c:.1f}')\n",
    "            if j == 0:\n",
    "                ax.set_ylabel(f\"Trial {i+1}\")\n",
    "            \n",
    "    plt.title(f'Sensitive Split {censor_split}')\n",
    "    plt.tight_layout()\n",
    "    return plt\n",
    "    #plt.show()\n",
    "\n",
    "def plot_multiple_parity_plots(censor_split, censor_type, censor_intervals, results_dir=None):\n",
    "    task = f'{censor_type}_results_split{censor_split}_{censor_region}'\n",
    "    if results_dir == None:\n",
    "        results_dir = f'../all_results/gcn_{task}'\n",
    "    \n",
    "    labels = [label for _, label in data]\n",
    "    threshold = compute_threshold_from_split(labels, censor_split, censor_region)\n",
    "    \n",
    "    ncols = len(censor_intervals)\n",
    "    fig, axs = plt.subplots(nrows=5, ncols=ncols, sharey=True, figsize=(ncols*2+5, 12), dpi=300)\n",
    "    \n",
    "    for i in range(5):  # Trials from 0 to 4\n",
    "        for j, c in enumerate(censor_intervals):  # Omit fractions from 0.0 to 1.0\n",
    "            ax = axs[i,j]\n",
    "            file_name = f'{results_dir}/parityplotdata_trial{i}_{censor_type}_{c}.json'\n",
    "            with open(file_name, 'r') as file:\n",
    "                rmse, lower_rmse, upper_rmse, corr, lower_corr, upper_corr, ytest, yhat = json.load(file)\n",
    "\n",
    "            ytest_t, yhat_t = torch.tensor(ytest), torch.tensor(yhat)\n",
    "            upper_ytest = ytest_t[ytest_t >= threshold]\n",
    "            lower_ytest = ytest_t[ytest_t < threshold]\n",
    "            upper_yhat = yhat_t[ytest_t >= threshold]\n",
    "            lower_yhat = yhat_t[ytest_t < threshold] \n",
    "\n",
    "            # note: assume upper local region is sensitive region\n",
    "            ax.plot([-2, 5], [-2, 5], c='black')\n",
    "            ax.scatter(upper_ytest, upper_yhat, label='sensitve', s=1, c='C1')\n",
    "            ax.scatter(lower_ytest, lower_yhat, s=1, label='non-sensitive', c='C0')\n",
    "            ax.text(0,0, f'corr={upper_corr:.3f}', c='C1')\n",
    "            ax.text(0,-1, f'corr={lower_corr:.3f}', c='C0')\n",
    "            ax.set_xlim(-2,5)\n",
    "            ax.set_ylim(-2,5)\n",
    "            if i == 0:\n",
    "                if censor_type == 'omit':\n",
    "                    ax.set_title(f'Omit Fraction {c:.1f}')\n",
    "                elif censor_type == 'xnoise':\n",
    "                    ax.set_title(f'Similarity {c}')\n",
    "                else: \n",
    "                    ax.set_title(f'Y Noise level {c:.1f}')\n",
    "            if j == 0:\n",
    "                ax.set_ylabel(f\"Trial {i+1}\")\n",
    "            \n",
    "    plt.title(f'Sensitive Split {censor_split}')\n",
    "    plt.tight_layout()\n",
    "    return plt\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd30c1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "omit_fractions = np.linspace(0, 1, int(1/0.1+1))\n",
    "print('omit fractions', omit_fractions)\n",
    "censor_intervals = omit_fractions\n",
    "\n",
    "for split in censor_splits:\n",
    "    plt = plot_multiple_training_curves(split, 'omit', censor_intervals)\n",
    "    plt.savefig(f'paper_figs/training_curves/training_curves_omit_split_{split}.svg', dpi = 300)\n",
    "    plt.close()\n",
    "    \n",
    "    plt = plot_multiple_parity_plots(split, 'omit', censor_intervals)\n",
    "    plt.savefig(f'paper_figs/parity_plots/parity_plots_omit_split_{split}.svg', dpi = 300)\n",
    "    plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b84b4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_scores = [\n",
    "    [1.0, 1.0], # no-noise control\n",
    "    [0.8, 1.0],\n",
    "    [0.7, 0.8],\n",
    "    [0.6, 0.7],\n",
    "    [0.5, 0.6],\n",
    "    [0.4, 0.5],\n",
    "    [0.35, 0.4],\n",
    "    [0.3, 0.35],\n",
    "    [0.25, 0.3],\n",
    "    [0.2, 0.25],\n",
    "    [0.15, 0.2],\n",
    "    [0.1, 0.15],\n",
    "    [0.05, 0.1],\n",
    "    [0, 0.05],\n",
    "]\n",
    "censor_intervals = [f\"{s[0]}-{s[1]}\" for s in sim_scores]\n",
    "censor_type = 'xnoise'\n",
    "\n",
    "for split in censor_splits:\n",
    "    plt = plot_multiple_training_curves(split, censor_type, censor_intervals)\n",
    "    plt.savefig(f'paper_figs/training_curves/training_curves_{censor_type}_split_{split}.png', dpi = 300)\n",
    "    #plt.close()\n",
    "    \n",
    "    plt = plot_multiple_parity_plots(split, censor_type, censor_intervals)\n",
    "    plt.savefig(f'paper_figs/parity_plots/parity_plots_{censor_type}_split_{split}.png', dpi = 300)\n",
    "    #plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c12a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "interval_step = 0.2\n",
    "start_level = 0\n",
    "end_level = 5\n",
    "\n",
    "y_noise_levels = np.linspace(start_level, end_level, int((end_level - start_level) / interval_step + 1))\n",
    "censor_intervals = y_noise_levels\n",
    "censor_type = 'ynoise'\n",
    "\n",
    "for split in censor_splits:\n",
    "    plt = plot_multiple_training_curves(split, censor_type, censor_intervals)\n",
    "    plt.savefig(f'paper_figs/training_curves/training_curves_{censor_type}_split_{split}.png', dpi = 300)\n",
    "    #plt.close()\n",
    "    \n",
    "    plt = plot_multiple_parity_plots(split, censor_type, censor_intervals)\n",
    "    plt.savefig(f'paper_figs/parity_plots/parity_plots_{censor_type}_split_{split}.png', dpi = 300)\n",
    "    #plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dualusage",
   "language": "python",
   "name": "dualusage"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
