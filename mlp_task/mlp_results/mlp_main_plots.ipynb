{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbc0f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime\n",
    "\n",
    "import cairosvg\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import skunk\n",
    "import torch\n",
    "from matplotlib.offsetbox import AnnotationBbox\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "\n",
    "sys.path.insert(1, '/path/to/application/app/folder')\n",
    "today_date = datetime.today().date()\n",
    "time_now = datetime.today().ctime()\n",
    "\n",
    "# packages for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as font_manager\n",
    "import urllib.request\n",
    "\n",
    "urllib.request.urlretrieve('https://github.com/google/fonts/raw/main/ofl/ibmplexmono/IBMPlexMono-Regular.ttf', 'IBMPlexMono-Regular.ttf')\n",
    "fe = font_manager.FontEntry(\n",
    "    fname='IBMPlexMono-Regular.ttf',\n",
    "    name='plexmono')\n",
    "font_manager.fontManager.ttflist.append(fe)\n",
    "plt.rcParams.update({'axes.facecolor':'#f5f4e9',\n",
    "            'grid.color' : '#AAAAAA',\n",
    "            'axes.edgecolor':'#333333',\n",
    "            'figure.facecolor':'#FFFFFF',\n",
    "            'axes.grid': False,\n",
    "            'axes.prop_cycle':   plt.cycler('color', plt.cm.Dark2.colors),\n",
    "            'font.family': fe.name,\n",
    "            'figure.figsize': (3.5,3.5 / 1.2),\n",
    "            'ytick.left': True,\n",
    "            'xtick.bottom': True   ,\n",
    "            'figure.dpi': 300\n",
    "           })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b10e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "censor_region = \"above\"\n",
    "censor_splits = [0.1, 0.5, 0.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28a4d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "import re\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "def local_spearman(y, yhat, threshold, above=True):\n",
    "    # Filter y and yhat based on the threshold\n",
    "    if above:\n",
    "        mask = np.array(y) > threshold\n",
    "    else:\n",
    "        mask = np.array(y) <= threshold\n",
    "\n",
    "    local_y = np.array(y)[mask]\n",
    "    local_yhat = np.array(yhat)[mask]\n",
    "\n",
    "    if len(local_y) > 1:  # Ensure there are at least 2 data points\n",
    "        corr, _ = spearmanr(local_y, local_yhat)\n",
    "        return corr\n",
    "    else:\n",
    "        return np.nan  # Not enough data points for a valid correlation\n",
    "\n",
    "\n",
    "def inset_fig_placeholder(i, ax, xy, censor_type, no_noise=True):\n",
    "    '''\n",
    "    Placing empty annotation boxes for 2nd inset figure in each subplot\n",
    "    Can be before, during, or after 'process_and_plot'\n",
    "    \n",
    "    Steps\n",
    "    1. plot inset figures & save using savefig('filename.svg') -- done\n",
    "    2. make skunk annotation boxes\n",
    "    3. use skunk.insert to insert figures --> last, after legend is added\n",
    "    '''\n",
    "    \n",
    "    # place inset figure holder\n",
    "    if no_noise:\n",
    "        name_box = f'{censor_type}_no-noise{i}'\n",
    "        connectionstyle=\"arc3,rad=-0.2\"\n",
    "        #xybox = (0.03, 0.97) # left top corner\n",
    "        xybox = (0.01,0.97)\n",
    "    else:\n",
    "        name_box = f'{censor_type}_max-noise{i}'\n",
    "        connectionstyle=\"arc3,rad=0.2\"\n",
    "        #xybox = (0.73, 0.97) # right top corner\n",
    "        xybox = (0.76, 0.97)\n",
    "    #box = skunk.Box(75,75, name_box)\n",
    "    box = skunk.Box(45, 45, name_box)\n",
    "    ab = AnnotationBbox(box, xy, # where it points\n",
    "                        xybox=xybox, # where the box is located\n",
    "                        xycoords='data',\n",
    "                        boxcoords=(\"axes fraction\", \"axes fraction\"),\n",
    "                        box_alignment=(0,1),\n",
    "                        arrowprops=dict(arrowstyle='->,head_length=0.4,head_width=0.2',\n",
    "                                        connectionstyle=connectionstyle, \n",
    "                                        fc=\"w\",))\n",
    "    ax.add_artist(ab)\n",
    "    return ax\n",
    " \n",
    "    \n",
    "def make_parity_plot(censor_type, censor_split, censor_region, censor_interval):\n",
    "    # helper function to make parity plots for inset figures\n",
    "    file_name = f'all_results/mlp_{censor_type}_results_split{censor_split}_{censor_region}/history.json'\n",
    "    with open(file_name, 'r') as f:\n",
    "        content = f.read()\n",
    "    parts = re.split(r'\\nRun from today: .*\\[\\n', content)\n",
    "    all_trials_results = json.loads('['+ parts[1]) # just get the first run\n",
    "    \n",
    "    if censor_type == 'omit':\n",
    "        task = f'omit {int(censor_interval*100)}%'\n",
    "    elif censor_type == 'xnoise':\n",
    "        task = f'xn_level{censor_interval:0.1f}'\n",
    "    elif censor_type == 'ynoise':\n",
    "        task = f'y noise level {censor_interval:0.1f}'\n",
    "    else:\n",
    "        raise KeyError(f'Unknown censor_type: {censor_type}')\n",
    "    \n",
    "    result = all_trials_results[0] # grab the first trial\n",
    "    threshold = result['censor_threshold']\n",
    "    ytest = result['y_test']\n",
    "    yhat = result['pred'][task]\n",
    "    \n",
    "    \n",
    "    fig1, ax1 = plt.subplots(figsize=(1,1))\n",
    "    ytest_t, yhat_t = torch.tensor(ytest), torch.tensor(yhat)\n",
    "    upper_ytest = ytest_t[ytest_t >= threshold]\n",
    "    lower_ytest = ytest_t[ytest_t < threshold]\n",
    "    upper_yhat = yhat_t[ytest_t >= threshold]\n",
    "    lower_yhat = yhat_t[ytest_t < threshold]\n",
    "    if censor_region == 'above':\n",
    "        lower_color = 'C0'\n",
    "        upper_color = 'C1'\n",
    "\n",
    "    else:\n",
    "        lower_color = 'C1'\n",
    "        upper_color = 'C0'\n",
    "    ax1.scatter(upper_ytest, upper_yhat, s=1, c=upper_color)\n",
    "    ax1.scatter(lower_ytest, lower_yhat, s=1, c=lower_color)\n",
    "    \n",
    "    min_val = min(ytest)\n",
    "    max_val = max(ytest)\n",
    "\n",
    "    # Set the limits based on the global min and max values\n",
    "    plt.xlim(min_val, max_val)\n",
    "    plt.ylim(min_val, max_val)\n",
    "\n",
    "    ax1.plot([min_val, max_val], [min_val, max_val], c='black', linewidth=0.5)\n",
    "    ax1.set_xlim(min_val, max_val)\n",
    "    ax1.set_ylim(min_val, max_val)\n",
    "\n",
    "    # remove ticks and tick labels to look simple\n",
    "    ax1.set_xticks([])\n",
    "    ax1.set_yticks([])\n",
    "\n",
    "    # save to svg file\n",
    "    svg_filename = f'figures/{task}_split{censor_split}_yt{threshold}.svg'\n",
    "    fig1.patch.set_alpha(0.0)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(svg_filename, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    return svg_filename\n",
    "\n",
    "def insert_skunk_figs(censor_types, censor_splits, censor_region, censor_intervals):\n",
    "    if isinstance(censor_types, str):\n",
    "        censor_types = [censor_types]\n",
    "        censor_intervals = [censor_intervals]\n",
    "    \n",
    "    skunk_dict={}\n",
    "    for j, ctype in enumerate(censor_types):\n",
    "        intervals = censor_intervals[j]\n",
    "        for i, split in enumerate(censor_splits):\n",
    "            # fig for point 0\n",
    "            svg_filename1 = make_parity_plot(ctype, split, censor_region, intervals[0])\n",
    "            skunk_dict[f'{ctype}_no-noise{i}'] = svg_filename1\n",
    "\n",
    "            # fig for last point\n",
    "            svg_filename2 = make_parity_plot(ctype, split, censor_region, intervals[-1])\n",
    "            skunk_dict[f'{ctype}_max-noise{i}'] = svg_filename2\n",
    "    svg = skunk.insert(skunk_dict)\n",
    "    return svg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e2e51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# updated plotting fxn\n",
    "def process_and_plot_mlp_with_inset_figs(i, ax, censor_split, censor_type, censor_intervals, tasks, metric='corr', title=True):\n",
    "    file_name = f'all_results/mlp_{censor_type}_results_split{censor_split}_{censor_region}/history.json'\n",
    "    with open(file_name, 'r') as f:\n",
    "        content = f.read()\n",
    "    parts = re.split(r'\\nRun from today: .*\\[\\n', content)\n",
    "    all_trials_results = json.loads('['+ parts[1]) # just get the first run\n",
    "    mean_all = []\n",
    "    mean_above = []\n",
    "    mean_below = []\n",
    "    std_all = []\n",
    "    std_above = []\n",
    "    std_below = []\n",
    "    for task in tasks:\n",
    "        spearman_correlations = []\n",
    "        correlations_above = []\n",
    "        correlations_below = []\n",
    "        for result in all_trials_results:\n",
    "            threshold = result['censor_threshold']\n",
    "            ytest = result['y_test']\n",
    "            yhat = result['pred'][task]\n",
    "            overall_corr, _ = spearmanr(ytest, yhat)\n",
    "            spearman_correlations.append(overall_corr) \n",
    "            correlations_above.append(local_spearman(ytest, yhat, threshold, above=True))\n",
    "            correlations_below.append(local_spearman(ytest, yhat, threshold, above=False))\n",
    "\n",
    "        mean_all.append(np.mean(spearman_correlations))\n",
    "        mean_above.append(np.mean(correlations_above)) \n",
    "        mean_below.append(np.mean(correlations_below))\n",
    "        std_all.append(np.std(spearman_correlations))\n",
    "        std_above.append(np.std(correlations_above))\n",
    "        std_below.append(np.std(correlations_below))\n",
    "\n",
    "    ax.plot(censor_intervals, mean_above, label='Sensitive data', marker='x', c='C1') # del \"markersize=2\"\n",
    "    ax.fill_between(\n",
    "        censor_intervals, np.subtract(mean_above, std_above), np.add(mean_above,std_above), alpha=0.2, color='C1')\n",
    "\n",
    "    ax.plot(censor_intervals, mean_below, label='Non-sensitive data', marker='^', color='C0') # del \"markersize=2\"\n",
    "    ax.fill_between(\n",
    "        censor_intervals, np.subtract(mean_below,std_below), np.add(mean_below,std_below), alpha=0.2, color='C0')\n",
    "     \n",
    "    # Placeholders for Inset Figures\n",
    "    no_noise_xcoord = censor_intervals[0]\n",
    "    max_noise_xcoord = censor_intervals[-1]\n",
    "        \n",
    "    # inset fig for no-noise parity plot, two arrows pointing at two curve regions\n",
    "    xy1a = (no_noise_xcoord, mean_above[0])\n",
    "    xy1b = (no_noise_xcoord, mean_below[0])\n",
    "    inset_fig_placeholder(i, ax, xy1a, censor_type, no_noise=True)\n",
    "    inset_fig_placeholder(i, ax, xy1b, censor_type, no_noise=True) # for 2nd arrow\n",
    "    \n",
    "    # inset fig for max-noise parity plot\n",
    "    xy2a = (max_noise_xcoord, mean_above[-1])\n",
    "    xy2b = (max_noise_xcoord, mean_below[-1])\n",
    "    inset_fig_placeholder(i, ax, xy2a, censor_type, no_noise=False)\n",
    "    inset_fig_placeholder(i, ax, xy2b, censor_type, no_noise=False)\n",
    "        \n",
    "    ax.autoscale(enable=True, axis='x', tight=True)\n",
    "    if metric == 'corr':\n",
    "        ax.set_ylim(0, 1.7)\n",
    "    else:\n",
    "        ax.set_ylim(0, 2.0)\n",
    "    ax.grid(True)\n",
    "    if title:\n",
    "        ax.set_title(f'{censor_split * 100:.0f}% sensitive data')\n",
    "        \n",
    "    return censor_intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f4ac86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_plot_mlp(ax, censor_split, censor_type, censor_intervals, tasks):\n",
    "    file_name = f'all_results/mlp_{censor_type}_results_split{censor_split}_{censor_region}/history.json'\n",
    "    with open(file_name, 'r') as f:\n",
    "        content = f.read()\n",
    "    parts = re.split(r'\\nRun from today: .*\\[\\n', content)\n",
    "    all_trials_results = json.loads('['+ parts[1]) # just get the first run\n",
    "    mean_all = []\n",
    "    mean_above = []\n",
    "    mean_below = []\n",
    "    std_all = []\n",
    "    std_above = []\n",
    "    std_below = []\n",
    "    for task in tasks:\n",
    "        spearman_correlations = []\n",
    "        correlations_above = []\n",
    "        correlations_below = []\n",
    "        for result in all_trials_results:\n",
    "            threshold = result['censor_threshold']\n",
    "            ytest = result['y_test']\n",
    "            yhat = result['pred'][task]\n",
    "            overall_corr, _ = spearmanr(ytest, yhat)\n",
    "            spearman_correlations.append(overall_corr) \n",
    "            correlations_above.append(local_spearman(ytest, yhat, threshold, above=True))\n",
    "            correlations_below.append(local_spearman(ytest, yhat, threshold, above=False))\n",
    "\n",
    "        mean_all.append(np.mean(spearman_correlations))\n",
    "        mean_above.append(np.mean(correlations_above)) \n",
    "        mean_below.append(np.mean(correlations_below))\n",
    "        std_all.append(np.std(spearman_correlations))\n",
    "        std_above.append(np.std(correlations_above))\n",
    "        std_below.append(np.std(correlations_below))\n",
    "\n",
    "    ax.plot(censor_intervals, mean_above, label='Sensitive data', marker='x', c='C1') # del \"markersize=2\"\n",
    "    ax.fill_between(\n",
    "        censor_intervals, np.subtract(mean_above, std_above), np.add(mean_above,std_above), alpha=0.2, color='C1')\n",
    "\n",
    "    ax.plot(censor_intervals, mean_below, label='Non-sensitive data', marker='^', color='C0') # del \"markersize=2\"\n",
    "    ax.fill_between(\n",
    "        censor_intervals, np.subtract(mean_below,std_below), np.add(mean_below,std_below), alpha=0.2, color='C0')\n",
    "\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_title(f'{censor_split * 100:.0f}% sensitive data')\n",
    "    #ax.grid(True)\n",
    "    \n",
    "def process_and_plot_mlp_rmse(ax, censor_split, censor_type, censor_intervals, tasks):\n",
    "    file_name = f'all_results/mlp_{censor_type}_results_split{censor_split}_{censor_region}/history.json'\n",
    "    with open(file_name, 'r') as f:\n",
    "        content = f.read()\n",
    "    parts = re.split(r'\\nRun from today: .*\\[\\n', content)\n",
    "    all_trials_results = json.loads('['+ parts[1]) # just get the first run\n",
    "    mean_all = []\n",
    "    mean_above = []\n",
    "    mean_below = []\n",
    "    std_all = []\n",
    "    std_above = []\n",
    "    std_below = []\n",
    "    for task in tasks:\n",
    "        overall_rmse = []\n",
    "        rmse_above = []\n",
    "        rmse_below = []\n",
    "        for result in all_trials_results:\n",
    "            overall_rmse.append(result['overall_error'][task])\n",
    "            rmse_above.append(result['upper_error'][task])\n",
    "            rmse_below.append(result['lower_error'][task])\n",
    "        \n",
    "        mean_all.append(np.mean(overall_rmse))\n",
    "        mean_above.append(np.mean(rmse_above)) \n",
    "        mean_below.append(np.mean(rmse_below))\n",
    "        std_all.append(np.std(overall_rmse))\n",
    "        std_above.append(np.std(rmse_above))\n",
    "        std_below.append(np.std(rmse_below))\n",
    "        \n",
    "    ax.plot(censor_intervals, mean_above, label='Sensitive data', marker='x' , c='C1') # del \"markersize=2\"\n",
    "    ax.fill_between(\n",
    "        censor_intervals, np.subtract(mean_above, std_above), np.add(mean_above,std_above), alpha=0.2, color='C1')\n",
    "\n",
    "    ax.plot(censor_intervals, mean_below, label='Non-sensitive data', marker='^', color='C0') # del \"markersize=2\"\n",
    "    ax.fill_between(\n",
    "        censor_intervals, np.subtract(mean_below,std_below), np.add(mean_below,std_below), alpha=0.2, color='C0')\n",
    "\n",
    "#     ax.plot(censor_intervals, mean_all, label='All data', marker='o', markersize=2, color='C2')\n",
    "#     ax.fill_between(\n",
    "#         censor_intervals, np.subtract(mean_all,std_all), np.add(mean_all,std_all), alpha=0.2, color='C2')\n",
    "\n",
    "    ax.set_ylim(0, 1.8)\n",
    "    ax.set_title(f'{censor_split * 100:.0f}% sensitive data', fontsize=12)\n",
    "    ax.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc9741b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine all MLP results\n",
    "\n",
    "# todo: try ylim(0,1) and place inset figures outside grid area\n",
    "def plot_everything():\n",
    "    combined_fig, axs = plt.subplots(3, 3, figsize=(10,10), sharey=True) # 3 splits for each of 3 censor types\n",
    "    ytitle = 'Spearman Correlation'\n",
    "    all_censor_intervals = []\n",
    "    \n",
    "    # plot omission results\n",
    "    omit_fractions = np.linspace(0, 1, int(1/0.1+1))\n",
    "    tasks = [f'omit {int(omit_frac*100)}%' for omit_frac in omit_fractions]\n",
    "    all_censor_intervals.append(omit_fractions)\n",
    "    axs[0,0].set_ylabel(ytitle, fontsize=12)\n",
    "    axs[0,1].set_xlabel('Percentage of Sensitive Data Omitted from Training Data\\n ', fontsize=16) #labelpad=10) #, fontsize=16)\n",
    "    for i, split in enumerate(censor_splits):\n",
    "        process_and_plot_mlp_with_inset_figs(i, axs[0,i], split, 'omit', omit_fractions, tasks)\n",
    "\n",
    "    # plot xnoise results\n",
    "    x_noise_levels = np.linspace(0, 2, int(2/0.1+1))\n",
    "    tasks = [f'xn_level{x:0.1f}' for x in x_noise_levels]\n",
    "    all_censor_intervals.append(x_noise_levels) \n",
    "    axs[1,0].set_ylabel(ytitle, fontsize=12)\n",
    "    axs[1,1].set_xlabel(r'Level of Feature Noise ($\\delta X$) Applied to Sensitive Data in Training Data' + '\\n ', fontsize=16) #, labelpad=10) #, fontsize=16)\n",
    "    for i, split in enumerate(censor_splits):\n",
    "        process_and_plot_mlp_with_inset_figs(i, axs[1,i], split, 'xnoise', x_noise_levels, tasks) #, title=False)\n",
    "\n",
    "    # plot ynoise results\n",
    "    y_noise_levels = np.linspace(0, 10, int(2/0.2+1))\n",
    "    tasks = [f'y noise level {y}' for y in y_noise_levels]\n",
    "    all_censor_intervals.append(y_noise_levels)\n",
    "    axs[2,0].set_ylabel(ytitle, fontsize=12)\n",
    "    axs[2,1].set_xlabel(r'Level of Label Noise ($\\delta y$) Applied to Sensitive Data in Training Data', fontsize=16) #, labelpad=10) #, fontsize=16)\n",
    "    for i, split in enumerate(censor_splits):\n",
    "        process_and_plot_mlp_with_inset_figs(i, axs[2,i], split, 'ynoise', y_noise_levels, tasks) #, title=False)\n",
    "    \n",
    "    plt.subplots_adjust(hspace=1.0)\n",
    "    legend_handles = [\n",
    "        plt.Line2D([0], [0], marker='x', color='C1', lw=2, label='Sensitive Labels'),\n",
    "        plt.Line2D([0], [0], marker='^', color='C0', lw=2, label='Non-sensitive Labels')\n",
    "    ]\n",
    "    combined_fig.legend(handles=legend_handles, bbox_to_anchor=(0.97, 0.06)) #, loc='center') #, bbox_to_anchor=(0.92, 0.5))\n",
    "    \n",
    "    combined_fig.tight_layout(rect=[0, 0.05, 1, 1]) #tight_layout(rect=[0, 0, 0.85, 1])\n",
    "    \n",
    "    svg = insert_skunk_figs(['omit', 'xnoise', 'ynoise'], censor_splits, censor_region, all_censor_intervals)\n",
    "    plt.close()\n",
    "    return svg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37017ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "svg = plot_everything()\n",
    "skunk.display(svg)\n",
    "\n",
    "with open('mlp_corr_with_all_titles_2024-12-31.svg', 'w') as f:\n",
    "    f.write(svg)\n",
    "\n",
    "cairosvg.svg2png(bytestring=svg, write_to='mlp_corr_with_all_titles_2024-12-31.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a0a7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# omission overview - RMSE\n",
    "\n",
    "censor_type = 'omit'\n",
    "omit_fractions = np.linspace(0, 1, int(1/0.1+1))\n",
    "tasks = [f'omit {int(omit_frac*100)}%' for omit_frac in omit_fractions]\n",
    "censor_intervals = omit_fractions \n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(18, 5))\n",
    "axs[0].set_ylabel('Test RMSE', fontsize=16)\n",
    "axs[1].set_xlabel('% sensitive data omitted from training data', labelpad=10, fontsize=16)\n",
    "\n",
    "for i, split in enumerate(censor_splits):\n",
    "    process_and_plot_mlp_rmse(axs[i], split, censor_type, censor_intervals, tasks)\n",
    "\n",
    "legend_handles = [\n",
    "    plt.Line2D([0], [0], marker='x', color='C1', lw=2, label='Sensitive Labels'),\n",
    "    plt.Line2D([0], [0], marker='^', color='C0', lw=2, label='Non-sensitive Labels')\n",
    "]\n",
    "fig.legend(handles=legend_handles, loc='center', bbox_to_anchor=(0.92, 0.5))\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 0.85, 1])\n",
    "plt.savefig('overview_mlp_omission_rmse.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eaa6cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x-noise overview - RMSE\n",
    "\n",
    "censor_type = 'xnoise'\n",
    "x_noise_levels = np.linspace(0, 2, int(2/0.1+1))\n",
    "tasks = [f'xn_level{x:0.1f}' for x in x_noise_levels]\n",
    "censor_intervals = x_noise_levels \n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(18, 5))\n",
    "axs[0].set_ylabel('Test RMSE', fontsize=16)\n",
    "axs[1].set_xlabel('Feature noise level applied to sensitive data in training data', labelpad=10, fontsize=16)\n",
    "\n",
    "for i, split in enumerate(censor_splits):\n",
    "    process_and_plot_mlp_rmse(axs[i], split, censor_type, censor_intervals, tasks)\n",
    "\n",
    "legend_handles = [\n",
    "    plt.Line2D([0], [0], marker='x', color='C1', lw=2, label='Sensitive Labels'),\n",
    "    plt.Line2D([0], [0], marker='^', color='C0', lw=2, label='Non-sensitive Labels')\n",
    "]\n",
    "fig.legend(handles=legend_handles, loc='center', bbox_to_anchor=(0.92, 0.5))\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 0.85, 1])\n",
    "plt.savefig('overview_mlp_xnoise_rmse.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f552b97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y-noise overview - RMSE\n",
    "\n",
    "censor_type = 'ynoise'\n",
    "y_noise_levels = np.linspace(0, 10, int(2/0.2+1))\n",
    "tasks = [f'y noise level {y}' for y in y_noise_levels]\n",
    "censor_intervals = y_noise_levels \n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(18, 5))\n",
    "axs[0].set_ylabel('Test RMSE', fontsize=16)\n",
    "axs[1].set_xlabel('Label noise level applied to sensitive data in training data', labelpad=10, fontsize=16)\n",
    "\n",
    "for i, split in enumerate(censor_splits):\n",
    "    process_and_plot_mlp_rmse(axs[i], split, censor_type, censor_intervals, tasks)\n",
    "\n",
    "legend_handles = [\n",
    "    plt.Line2D([0], [0], marker='x', color='C1', lw=2, label='Sensitive Labels'),\n",
    "    plt.Line2D([0], [0], marker='^', color='C0', lw=2, label='Non-sensitive Labels')\n",
    "]\n",
    "fig.legend(handles=legend_handles, loc='center', bbox_to_anchor=(0.92, 0.5))\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 0.85, 1])\n",
    "plt.savefig('overview_mlp_ynoise_rmse.png', dpi=300)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dualusage",
   "language": "python",
   "name": "dualusage"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
